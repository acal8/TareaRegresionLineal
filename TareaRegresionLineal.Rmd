---
title: "Tarea: Modelos de regresión lineal simple y múltiple"
subtitle: "Aprendizaje Máquina (I). Máster en Ciencia de Datos - UV"
author: "Adrián Carrasco Alcalá y Clara Montalvá Barcenilla"
date: "Curso 2025-2026"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

En la librería `MASS` puedes encontrar un famoso banco de datos llamado `Boston` que contiene información sobre 506 barrios de Boston, Massachusetts, en 1970. La base de datos contiene 14 variables relativas a 506 barrios. Para saber qué información está contenida en las variables puedes escribir `?Boston` (después de haber cargado la librería `MASS`).

En esta tarea trabajaremos con el conjunto de datos “boston.xlsx” que encontraréis en el aula virtual (con 199 datos y 11 variables).

```{r, echo = FALSE}
library(readxl)
boston <- read_excel("boston.xlsx")
```

---

<u>Ejercicio 1:</u> Considera la variable respuesta `crim` relacionándola con la variable `X` con la que tenga mayor relación lineal.

```{r}
lm_crim_global <- lm(crim ~. , data=boston)
summary(lm_crim_global)
```
Observamos que la variable más significativa (la de p-valor más pequeño) es `lstat`, por lo que deducimos que es esta la variable con la que `crim` tiene mayor relación lineal. 

1. Evalúa el efecto de `X` sobre `crim`, gráficamente y numéricamente. Es decir, indica como es la relación (fuerza y tipo).

```{r}
lm_crim_lstat <- lm(crim ~ lstat, data=boston)
summary(lm_crim_lstat)
plot(boston$lstat, boston$crim, col='BLUE', xlab = 'lstat', ylab = 'crim')
```

Cuando `lstat` aumenta en una unidad, `crim` aumenta en `r lm_crim_lstat$coefficients[2]`. Vemos que pese a que la variable sea muy significativa, en el gráfico de dispersión se observa una relación de fuerza baja o moderada, ya que los puntos no se agrupan alrededor de ninguna recta y se identifica un aumento en la dispersión de `crim` a medida que `lstat` incrementa. Este efecto es un posible indicador de heterocedasticidad, ya que muestra que la varianza no es constante.

2. Obtén la recta de mínimos cuadrados. Interpreta los resultados obtenidos (coeficientes, significatividad, $R^2$, contraste del modelo, etc...).

```{r}
summary(lm_crim_lstat)
plot(boston$lstat, boston$crim, col='BLUE', main = "Diagrama de dispersión", xlab = 'lstat', ylab = 'crim')
abline(coef=coef(lm_crim_lstat), lwd = 2, col='RED')
```

Obtenemos la siguiente recta de mínimos cuadrados: $$\hat{\text{crim}} = -2.623 + 0.428 \, \, \text{lstat},$$

siendo $\beta_0 =$ `r lm_crim_lstat$coefficients[1]` el intercepto y $\beta_1 =$ `r lm_crim_lstat$coefficients[2]` la pendiente de la recta.

El p-valor del estadístico F es prácticamente $0$, por lo que rechazamos la hipótesis nula de que ninguna variable es significativa para explicar el modelo. Ahora bien, pese a que la variable `lstat` es muy significativa (al 0%) y la recta pasa por el "centro" de los datos, los puntos están muy dispersos alrededor de ella. Esto visualmente respalda el $R^2$ ajustado de $0.4055$ (menor que el del modelo global), confirmando que aún queda más de la mitad de la varianza del modelo por explicar.

Vemos también que la recta tiende a predecir valores negativos de `crim` para valores bajos de `lstat`, lo cual no tiene sentido si tenemos en cuenta que la variable `crim` mide la tasa de criminalidad en la ciudad. Tenemos una subestimación de `crim` para valores bajos y altos de `lstat` y una sobreestimación para valores medios. Además, la dispersión no uniforme de los datos y la concentración de puntos cerca de cero sugiere transformación logarítmica para la relación.

3. Dibuja el diagrama de dispersión, la recta de regresión y las bandas de confianza al 90%.

```{r}
# Obtención de las bandas de estimación
min <- range(boston$lstat)[1]; max <- range(boston$lstat)[2]
nuevos <- data.frame(list(lstat = seq(min,max,length=100)))
bandas_est <- predict(lm_crim_lstat, newdata = nuevos, interval = "confidence", level = 0.90)

# Representación gráfica 
plot(boston$lstat, boston$crim, col='BLUE', main = 'Diagrama de dispersión', xlab = 'lstat', ylab = 'crim')
abline(coef=coef(lm_crim_lstat), col='RED')
lines(nuevos$lstat, bandas_est[,2],col='BLACK')
lines(nuevos$lstat, bandas_est[,3],col='BLACK')
legend('topright', legend = c('Recta de regresión', 'Bandas de confianza al 90%'), lwd = 3, col = c('red', 'black'))
```

4. Realiza un diagnóstico de los residuos. Si falla alguna de las condiciones, busca una (o varias) posible solución.

```{r}
# Diagnóstico de linealidad y homocedasticidad
residuos <- residuals(lm_crim_lstat)
predichos <- fitted.values(lm_crim_lstat)
plot(predichos, residuos, col='BLUE', main = 'Gráfica de residuos')
abline(h=0, lty=2)

# Diagnóstico de normalidad de los residuos
qqnorm(residuos, col='BLUE')
qqline(residuos)
shapiro.test(residuos)
```

Siendo el resultado del p-valor prácticamente $0$ en el test de Shapiro_Wilk, rechazamos la hipótesis nula de normalidad de los residuos. Por tanto, hay evidencia estadística a favor de que los residuos no siguen una distribución normal.

En cuanto a las gráficas, la primera de ellas muestra la no linealidad de los residuos, ya que no aparecen como una nube aleatoria de puntos alrededor de la recta $y = 0$. Además, observamos que la varianza de los mismos aumenta a medida que incrementan los valores predichos, indicando un claro fallo de heterocedasticidad. La segunda gráfica confirma lo que deducido previamente del test de Shapiro-Wilk, es decir, que los residuos no siguen una distribución normal, debido a desviaciones importantes de la línea diagonal, especialmente en los extremos o colas. 

En conclusión, el modelo simple no es adecuado para estos datos debido a fallos en la linealidad, homocedasticidad y normalidad de los residuos. Una posible solución es aplicar una transformación logarítmica a la variable respuesta (`crim`) para estabilizar la varianza y mejorar el ajuste.

```{r}
# Aplicamos la transformación logarítmica
lm_crim_log <- lm(log(crim)~lstat, data = boston, na.action = na.exclude)
summary(lm_crim_log)

# Representamos el diagrama de dispersión junto con la recta de regresión y las bandas de estimación al 90%
min <- range(boston$lstat)[1]; max <- range(boston$lstat)[2]
nuevos <- data.frame(list(lstat = seq(min,max,length=100)))
bandas_est <- predict(lm_crim_log, newdata = nuevos, interval = "confidence", level = 0.90)

plot(boston$lstat, log(boston$crim), col='blue', main = 'Diagrama de dispersión transformación logarítmica', xlab = 'lstat', ylab = 'log(crim)', type = "p")
abline(coef = coef(lm_crim_log), col='RED')
lines(nuevos$lstat, bandas_est[,2],col='BLACK')
lines(nuevos$lstat, bandas_est[,3],col='BLACK')
legend('topright', legend = c('Recta de regresión', 'Bandas de confianza al 90%'), lwd = 3, col = c('red', 'black'))

# Diagnóstico de linealidad y homocedasticidad
residuos <- residuals(lm_crim_log)
predichos <- fitted.values(lm_crim_log)
plot(predichos, residuos, col='blue', main = 'Gráfica de residuos transformación logarítmica')
abline(h=0, lty=2)

# Diagnóstico de normalidad de los residuos
qqnorm(residuos, col='blue')
qqline(residuos)
shapiro.test(residuos)
```

Al realizar la transformación logarítmica, el coeficiente se entiende ahora como que por cada aumento de una unidad (un punto porcentual) en la población de nivel socioeconómico bajo (`lstat`), se espera que la tasa de criminalidad (`crim`) aumente aproximadamente en un `r round(lm_crim_log$coefficients[2] * 100`% promedio.

Observamos en el gráfico de dispersión que los puntos están distribuidos de forma mucho más homogénea alrededor de la recta. Además, en la gráfica de dispersión de los residuos detectamos la linealidad y homocedasticidad que buscábamos, al aparecer los residuos como una nube aleatoria de puntos alrededor de la recta horizontal y la varianza ser constante para todos los valores predichos. Por lo que pese a que el $R^2$ ligeramente menor (seguimos explicando algo más del 40% de la varianza), se puede considerar que los fallos del anterior modelo se han solucionado.

```{r}
# Aplicamos la transformación logarítmica
lm_crim_log <- lm(log(crim)~log(lstat), data = boston, na.action = na.exclude)
summary(lm_crim_log)

# Representamos el diagrama de dispersión junto con la recta de regresión y las bandas de estimación al 90%
min <- range(boston$lstat)[1]; max <- range(boston$lstat)[2]
nuevos <- data.frame(list(lstat = seq(min,max,length=100)))
bandas_est <- predict(lm_crim_log, newdata = nuevos, interval = "confidence", level = 0.90)

plot(log(boston$lstat), log(boston$crim), col='blue', main = 'Diagrama de dispersión transformación logarítmica', xlab = 'log(lstat)', ylab = 'log(crim)', type = "p")
abline(coef = coef(lm_crim_log), col='red')
lines(log(nuevos$lstat), bandas_est[,2],col='BLACK')
lines(log(nuevos$lstat), bandas_est[,3],col='BLACK')
legend('topright', legend = c('Recta de regresión', 'Bandas de confianza al 90%'), lwd = 3, col = c('red', 'black'))

# Diagnóstico de linealidad y homocedasticidad
residuos <- residuals(lm_crim_log)
predichos <- fitted.values(lm_crim_log)
plot(predichos, residuos, col='BLUE', main = 'Gráfica de residuos transformación logarítmica')
abline(h=0, lty=2)

# Diagnóstico de normalidad de los residuos
qqnorm(residuos, col='BLUE')
qqline(residuos)
shapiro.test(residuos)
```

Al realizar una doble transformación logarítmica (sobre la variable predictora y sobre la de respuesta), el coeficiente se entiende ahora como por cada aumento del 1% en el porcentaje de población de nivel socioeconómico bajo (`lstat`), se espera que la tasa de criminalidad (`crim`) aumente en aproximadamente `r round(lm_crim_log$coefficients[2], 2)`%. Además, el gráfico muestra que los puntos están distribuidos de forma mucho más homogénea alrededor de la recta, por lo que pese a que el $R^2$ sea menor, se puede considerar que los fallos del anterior modelo se han solucionado.

<u>Ejercicio 2:</u> Considera la variable respuesta `crim` relacionándola con el predictor `medv`.

1. Evalúa el efecto de `medv` sobre `crim`.

```{r}
lm_crim_medv <- lm(crim ~ medv, data = boston)
summary(lm_crim_medv)
```

La variable predictora `medv`, que es muy significativa (al 0%), tiene un efecto negativo sobre `crim`; cuando `medv` aumenta una unidad, `crim` se reduce en `r -lm_crim_medv$coefficients[2]`.

Cuando `lstat` aumenta en una unidad, `crim` aumenta en `r lm_crim_lstat$coefficients[2]`. Vemos que pese a que la variable sea muy significativa, en el gráfico de dispersión se observa una relación de fuerza baja o moderada, ya que los puntos no se agrupan alrededor de ninguna recta y se identifica un aumento en la dispersión de `crim` a medida que `lstat` incrementa. Este efecto es un posible indicador de heterocedasticidad, ya que muestra que la varianza no es constante.

2. Obtén la recta de mínimos cuadrados. Interpreta los resultados obtenidos (coeficientes, significatividad, $R^2$, contraste del modelo, etc...).

La recta de mínimos cuadrados es: 8.518 -0.255B1
Como se ha comentado en el apartado anterior, aparentemente medv es muy significativa y si aumenta una unidad, crim disminuye en 0.2550. El F-statistic rechaza la hipótesis nula de que ninguna variable es significativa. Sin embargo, el R2 es muy bajo por lo que la varianza del modelo no está siendo explicada. 


```{r}
residuos2 <- residuals(lm_crim_lstat)
predichos <- fitted.values(lm_crim_lstat)
par(mfcol=c(1,2))
plot(predichos,residuos, col='BLUE',main = 'Gráfica de residuos')
abline(h=0,lty=2)

# diagnóstico normalidad residuos
qqnorm(residuos, col='BLUE')
qqline(residuos)
shapiro.test(residuos)
```


3. Dibuja el diagrama de dispersión, la recta de regresión y las bandas de predicción al 90%.
```{r}
#bandas estimación
min2<-range(boston$medv)[1]; max2<-range(boston$medv)[2]
nuevos2 <- data.frame(list(medv = seq(min2,max2,length=100)))
bandas_est2<-predict(lm_crim_medv, newdata = nuevos2, interval = "prediction", level = 0.90)

#representacion 
plot(boston$medv, boston$crim, col='BLUE')
abline(coef=coef(lm_crim_medv), col='RED')
lines(nuevos2$medv, bandas_est2[,2],col='BLACK')
lines(nuevos2$medv, bandas_est2[,3],col='BLACK')

```


4. Realiza un análisis de los residuos.
```{r}
# diagnóstico linealidad y homocedasticidad
residuos2 <- residuals(lm_crim_medv)
predichos2 <- fitted.values(lm_crim_medv)
par(mfcol=c(1,2))
plot(predichos2,residuos2, col='BLUE',main = 'Gráfica de residuos')
abline(h=0,lty=2)

# diagnóstico normalidad residuos
qqnorm(residuos2, col='BLUE')
qqline(residuos2)
shapiro.test(residuos2)
```

Observando el resultado del p-value < 0 en el Shapiro_Wilk test, rechazamos la hipótesis nula de normalidad y confirmamos que los residuos no siguen una distribución normal. 
En cuanto a las gráficas, la primera muestra que la relación no es puramente lineal ya que la dispersión de los residuos se amplía a medida que los valores predichos aumentan y forman una especie de U invertida, representando un fallo de heterocedasticidad. La segunda gráfica, confirma que los residuos no siguen una distribución normal, debido a desviaciones importantes de la línea diagonal, especialmente en los extremos. 

5. ¿Te parece adecuado haber realizado regresión lineal o es preferible otro tipo de regresión?. Ajusta el modelo que te parezca más adecuado.

El modelo simple no es adecuado debido a fallos en la linealidad, homocedasticidad y normalidad, lo que sería necesario aplicar una transformación cuadrática (viendo la forma de la dispersión de los residuos) para estabilizar la varianza y mejorar el ajuste.
```{r}
# Planteamos una solución con una transformación sqrt sobre las x y logarítimica sobre y
lm_medv_trans <- lm(crim ~ (medv+(I(medv)^2)), data = boston)

#Resumen Modelo
summary(lm_medv_trans)

#Representación del ajuste
plot((boston$medv + (I(boston$medv)^2)), (boston$crim), main = "Diagrama de dispersión", xlab = "medv con transformación sqrt", ylab = "crim con transformación logarítmica")
abline(coef=coef(lm_medv_trans), col='RED')

#Cálculo de residuos
residuos_trans <-residuals(lm_medv_trans)

# diagnóstico linealidad y homocedasticidad
predichos_trans <- fitted.values(lm_medv_trans)

plot(predichos_trans, residuos_trans, col='BLUE', main = 'Gráfica de residuos con transformaciones')
abline(h = 0, lty = 2)

# diagnóstico normalidad residuos
qqnorm(residuos_trans, col='BLUE')
qqline(residuos_trans)
```


6. ¿Qué tasa de criminalidad se espera para aquellos barrios con un precio mediano de la vivienda de 30000 dólares? ¿Y 10000? ¿Y 100000? Calcula e interpreta los intervalos de confianza y de predicción.
```{r}
predict.lm(lm_medv_trans,newdata=data.frame(medv=c(30, 10, 100)), se=T)
medv_pred<-predict(lm_medv_trans, newdata=data.frame(medv=c(30, 10, 100)), interval ="prediction")
medv_conf<-predict(lm_medv_trans, newdata=data.frame(medv=c(30, 10, 100)), interval ="confidence")

```


<u>Ejercicio 3:</u>

1. Encuentra el número óptimo de variables a incluir en un modelo predictivo de `crim`, según los criterios $R^2$, BIC y CP, utilizando la metodología RegSubsets. Indica brevemente en que consiste esta metodología.
```{r}
library(MASS)
library(leaps) 
library(readxl)
boston <- read_excel("boston.xlsx")
reg_crim<-regsubsets(crim ~ ., data = boston)
summary<-summary(reg_crim)

```

```{r}
lm1<-lm(crim ~ lstat, data=boston)
lm2<-lm(crim ~ ptratio + lstat, data=boston)
lm3<-lm(crim ~ ptratio + lstat + nox, data=boston)
lm4<-lm(crim ~ ptratio + lstat + rm + indus, data=boston)
lm5<-lm(crim ~ ptratio + lstat + rm + indus + chas, data=boston)
lm6<-lm(crim ~ ptratio + lstat + rm + indus + chas + medv, data=boston)
lm7<-lm(crim ~ ptratio + lstat + rm + indus + chas + medv + dis, data=boston)
lm8<-lm(crim ~ ptratio + lstat + rm + indus + chas + medv + dis + age, data=boston)

summary(lm1)
summary(lm2)
summary(lm3)
summary(lm4)
summary(lm5)
summary(lm6)
summary(lm7)
summary(lm8)
```

```{r}

resultado <- cbind(summary$rsq,summary$adjr2,summary$cp,summary$bic)
colnames(resultado) <- c('Rsq','RsqAdj','Cp','BIC')

length(summary$adjr2)

par(mfrow = c(1,3))
plot(1:8, summary$adjr2, xlab = "Variables", main = "Coef. Det. Ajustado",
     type="b")
abline(v = which.max(summary$adjr2), col = 2)
plot(1:8, summary$cp, xlab = "Variables", main = "Cp de Mallows",
     type='b')
abline(v = which.min(summary$cp), col = 2)
plot(1:8, summary$bic, xlab = "Variables", main = "BIC",
     type = "b")
abline(v = which.min(summary$bic), col = 2)
par(mfrow=c(1,1))

AIC(lm1,lm2,lm3,lm4,lm5,lm6,lm7,lm8)
```

  Observamos que el modelo 5 tiene el valor de BIC más bajo (-142.41) y el modelo 8 el AIC más bajo (990.59), por lo que significa que son los modelos que mejor equilibran el ajuste. EL modelo 8 contiene el R2 ajustado más elevado pese a tener age como variable no significativa, por lo que es el que mejor explica la varianza de la variable respuesta. 
Por último, el modelo 8 tiene el CP de Mallows más bajo por lo que tiene menor error de predicción. 
Teniendo en cuenta estos resultados, podríamos elegir como mejor modelo el 5, por penalización de complejidad (menos variables) o el modelo 8 si preferimos una predicción más exacta ya que el BIC suele ser mejor en modelos más simples (como en el 5).

  - ¿Qué variables incluye el modelo obtenido? (Seleccionar el criterio que más os guste). Interpreta los coeficientes obtenidos. ¿Tienen todas sentido?. ¿Son significativos?.
  
El modelo final incluye 8 variables: ptratio, lstat, rm, indus, chas, medv, dis y age. 
La mayoria de los coeficientes tienen la dirección esperada. Las características de desventaja (ptratio, lstat, indus) aumentan crim (signo positivo), mientras que las características de ventaja (chas, medv, dis) lo disminuyen (signo negativo). El coeficiente de rm (número promedio de habitaciones) es positivo.  Esto va en contra de la expectativa de que más habitaciones (casas mas grandes/caras) indicarian mayor riqueza y, por lo tanto, menor criminalidad. Esto sugiere que rm está correlacionada con alguna otra variable.

2. Selecciona el mejor modelo con el método stepwise. Indica brevemente en que consiste esta
metodología y contesta a las siguientes preguntas:

  - ¿Qué modelo piensas que es mejor? (Entre este y el/los obtenido/s mediante Regsubsets).
```{r}
crim_global<-lm(crim ~., data = boston)
step_crim<- step(crim_global, direction = 'both',trace=0) 
summary(step_crim)
```

   Coincide con una de las opciones planteadas con la otra metodología (modelo 8), de acuerdo con los estadísticos contrastados, por lo que este modelo sería la mejor opción.

  - ¿Qué % de la varianza de `crim` explica el modelo?
  
    El modelo con stepwise se compone de 8 variables y explica un 60% de la variación en la tasa de criminalidad (crim). La mayoria de los predictores son muy significativos, exceptuando la variable age.

  - ¿Cuál es el efecto de la variable `chas` sobre `crim`?
  
    El coeficiente de chas -2.23558 significa que, manteniendo todas las demás variables constantes, las areas que colindan con el río Charles (chas = 1) tienen una tasa de criminalidad 2,24 unidades menor que las areas que no coinciden con el río.

3. Con el modelo obtenido con stepwise, realiza el diagnóstico de tu modelo, sin emprender ninguna acción, e indica los problemas que presenta.

Repetimos que las variables explican un 60% de la varianza del modelo y que este en su conjunto es altamente significativo (F-estadistico con un p-value cercano a 0). Esto indica que al menos una de las variables predictoras es útil para el modelo.
  Las variables indus, chas, rm, ptratio, y lstat son las que tienen el impacto más significativo en la predicción de la tasa de criminalidad. La variable age no es estadísticamente significativa, lo que hace que su inclusión no mejora significativamente la predicción del modelo.
Se podría considerar hacer un modelo final eliminando age y rm por su supuesta multicolinealidad mencionada anteriormente para ver si esto mejora el R-cuadrado ajustado. 

4. Emprende ahora las acciones que te parezcan oportunas e indica los problemas que has conseguido solucionar o mejorar un poco.

```{r}
lm_crim_nuevo <- lm(crim ~ lstat + indus + chas + dis + ptratio + medv, data=boston)
summary(lm_crim_nuevo)
```
Eliminando las dos variables mencionadas anteriormente, vemos que ahora medv deja de ser significativa. La eliminamos y volvemos a hacer la regresión.

```{r}
lm_crim_nuevo <- lm(crim ~ lstat + indus + chas + dis + ptratio, data=boston)
summary(lm_crim_nuevo)
```

Ahora vemos que todas las variables son significativas y sus coeficientes tienen sentido. Además el R2 es mayor de 50% y el estadistico F confirma que al menos una de las variables es significativa.

5. Obtén la predicción de la tasa de criminalidad para un barrio en la mediana de los predictores en el modelo escogido. _Notar que las variables categóricas se tratan de diferente manera, no hay mediana_.